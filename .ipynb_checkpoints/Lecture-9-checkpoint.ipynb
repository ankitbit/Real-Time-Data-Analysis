{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa6ea029",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['PYSPARK_SUBMIT_ARGS'] = '--packages org.apache.spark:spark-streaming-kafka-0-8_2.11:2.0.2 pyspark-shell'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "83c90eaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.7.10\r\n"
     ]
    }
   ],
   "source": [
    "! python3 --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ab1c400",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/usr/local/Cellar/apache-spark/3.1.1/libexec/jars/spark-unsafe_2.12-3.1.1.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Welcome to\n",
      "      ____              __\n",
      "     / __/__  ___ _____/ /__\n",
      "    _\\ \\/ _ \\/ _ `/ __/  '_/\n",
      "   /___/ .__/\\_,_/_/ /_/\\_\\   version 3.1.1\n",
      "      /_/\n",
      "                        \n",
      "Using Scala version 2.12.10, OpenJDK 64-Bit Server VM, 11.0.10\n",
      "Branch HEAD\n",
      "Compiled by user ubuntu on 2021-02-22T01:33:19Z\n",
      "Revision 1d550c4e90275ab418b9161925049239227f3dc9\n",
      "Url https://github.com/apache/spark\n",
      "Type --help for more information.\n"
     ]
    }
   ],
   "source": [
    "! spark-shell --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5e60cca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import explode\n",
    "from pyspark.sql.functions import split\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"StructuredNetworkWordCount\") \\\n",
    "    .getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ec879869",
   "metadata": {},
   "outputs": [],
   "source": [
    "#    Spark\n",
    "from pyspark import SparkContext\n",
    "#    Spark Streaming\n",
    "from pyspark.streaming import StreamingContext\n",
    "#    Kafka\n",
    "from pyspark.streaming.dstream import DStream\n",
    "#    json parsing\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "66a5c959",
   "metadata": {},
   "outputs": [
    {
     "ename": "NoBrokersAvailable",
     "evalue": "NoBrokersAvailable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNoBrokersAvailable\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-70d9da55543a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mkafka\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKafkaClient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0mproducer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKafkaProducer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStdOutListener\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/kafka/client_async.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, **configs)\u001b[0m\n\u001b[1;32m    242\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'api_version'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m             \u001b[0mcheck_timeout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'api_version_auto_timeout_ms'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 244\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'api_version'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_version\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_timeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    245\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_can_bootstrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/kafka/client_async.py\u001b[0m in \u001b[0;36mcheck_version\u001b[0;34m(self, node_id, timeout, strict)\u001b[0m\n\u001b[1;32m    898\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtry_node\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 900\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mErrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNoBrokersAvailable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    901\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_connect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtry_node\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m             \u001b[0mconn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtry_node\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNoBrokersAvailable\u001b[0m: NoBrokersAvailable"
     ]
    }
   ],
   "source": [
    "from tweepy.streaming import StreamListener\n",
    "from tweepy import OAuthHandler\n",
    "from tweepy import Stream\n",
    "from kafka import KafkaClient, KafkaProducer\n",
    "\n",
    "access_token = \"1288431932-4VI3EA7vpL7FrnKnu61tyYvMIVy7Bh3rDA6ulqS\"\n",
    "access_token_secret =  \"krPnYxZgtPFAXnvMSfuw3dOQTvQ5dSAsdyCfq6wDx6UXn\"\n",
    "consumer_key =  \"1Lj8DS1pWpS1FhnqZTBVjunEU\"\n",
    "consumer_secret =  \"DVtoIgkxXPQa7xzGKa79xc8STxQn444kfLOdTuICD13Wr3VQoH\"\n",
    "\n",
    "class StdOutListener(StreamListener):\n",
    "    def on_data(self, data):\n",
    "        producer.send(\"trump\", data.encode('utf-8'))\n",
    "        print(data)\n",
    "        return True\n",
    "    def on_error(self, status):\n",
    "        print(status)\n",
    "\n",
    "kafka = KafkaClient()\n",
    "producer = KafkaProducer()\n",
    "l = StdOutListener()\n",
    "auth = OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "stream = Stream(auth, l)\n",
    "\n",
    "print(json.loads(stream.filter(track=\"BloodMatters\"))['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6ccf8801",
   "metadata": {},
   "outputs": [],
   "source": [
    "data= {\"created_at\":\"Mon Apr 19 20:13:21 +0000 2021\",\"id\":1384238710443548675,\"id_str\":\"1384238710443548675\",\"text\":\"@EuricSanti @ricardomendezc Soy y vivo en La Romnvana, y tengo entendido que eso no se le h pedido.\\n\\nA los que vend\\u2026 https:\\/\\/t.co\\/ly87VmJ6Yp\",\"display_text_range\":[28,140],\"source\":\"\\u003ca href=\\\"http:\\/\\/twitter.com\\/download\\/android\\\" rel=\\\"nofollow\\\"\\u003eTwitter for Android\\u003c\\/a\\u003e\",\"truncated\":True,\"in_reply_to_status_id\":1384229228166533123,\"in_reply_to_status_id_str\":\"1384229228166533123\",\"in_reply_to_user_id\":73097979,\"in_reply_to_user_id_str\":\"73097979\",\"in_reply_to_screen_name\":\"EuricSanti\",\"user\":{\"id\":218740138,\"id_str\":\"218740138\",\"name\":\"Alberto J. Damaso S. \\u00a1Carambola!\\ud83d\\udd27\",\"screen_name\":\"Albertodamaso18\",\"location\":\"La Romana Rep. Dom.\",\"url\":\"http:\\/\\/www.warketingnew.com\",\"description\":\"Esto no es LinkedIn... \\u00bfMe entendi\\u00f3? \\nPasi\\u00f3n + Perseverancia y raz\\u00f3n= eso har\\u00e1 que logres todo.\\n\\u00a1S\\u00e9 tu mismo!\\nAmo los mofongos, viajar, acampar, nadar y amar.\",\"translator_type\":\"none\",\"protected\":False,\"verified\":False,\"followers_count\":358,\"friends_count\":353,\"listed_count\":0,\"favourites_count\":15950,\"statuses_count\":9735,\"created_at\":\"Tue Nov 23 04:11:03 +0000 2010\",\"utc_offset\":None,\"time_zone\":None,\"geo_enabled\":True,\"lang\":None,\"contributors_enabled\":False,\"is_translator\":False,\"profile_background_color\":\"C0DEED\",\"profile_background_image_url\":\"http:\\/\\/abs.twimg.com\\/images\\/themes\\/theme1\\/bg.png\",\"profile_background_image_url_https\":\"https:\\/\\/abs.twimg.com\\/images\\/themes\\/theme1\\/bg.png\",\"profile_background_tile\":True,\"profile_link_color\":\"B34800\",\"profile_sidebar_border_color\":\"C0DEED\",\"profile_sidebar_fill_color\":\"DDEEF6\",\"profile_text_color\":\"333333\",\"profile_use_background_image\":True,\"profile_image_url\":\"http:\\/\\/pbs.twimg.com\\/profile_images\\/1328165946708684803\\/8i0lghh0_normal.jpg\",\"profile_image_url_https\":\"https:\\/\\/pbs.twimg.com\\/profile_images\\/1328165946708684803\\/8i0lghh0_normal.jpg\",\"profile_banner_url\":\"https:\\/\\/pbs.twimg.com\\/profile_banners\\/218740138\\/1612150477\",\"default_profile\":False,\"default_profile_image\":False,\"following\":None,\"follow_request_sent\":None,\"notifications\":None,\"withheld_in_countries\":[]},\"geo\":None,\"coordinates\":None,\"place\":None,\"contributors\":None,\"is_quote_status\":False,\"extended_tweet\":{\"full_text\":\"@EuricSanti @ricardomendezc Soy y vivo en La Romnvana, y tengo entendido que eso no se le h pedido.\\n\\nA los que vendemos los d\\u00edas de fiesta, nos conviene \\ud83e\\udd23\\ud83d\\ude02\\n.\\n.\\n#Carambolas\",\"display_text_range\":[28,171],\"entities\":{\"hashtags\":[{\"text\":\"Carambolas\",\"indices\":[160,171]}],\"urls\":[],\"user_mentions\":[{\"screen_name\":\"EuricSanti\",\"name\":\"Euric Santi\",\"id\":73097979,\"id_str\":\"73097979\",\"indices\":[0,11]},{\"screen_name\":\"ricardomendezc\",\"name\":\"Ricardo\",\"id\":61294918,\"id_str\":\"61294918\",\"indices\":[12,27]}],\"symbols\":[]}},\"quote_count\":0,\"reply_count\":0,\"retweet_count\":0,\"favorite_count\":0,\"entities\":{\"hashtags\":[],\"urls\":[{\"url\":\"https:\\/\\/t.co\\/ly87VmJ6Yp\",\"expanded_url\":\"https:\\/\\/twitter.com\\/i\\/web\\/status\\/1384238710443548675\",\"display_url\":\"twitter.com\\/i\\/web\\/status\\/1\\u2026\",\"indices\":[117,140]}],\"user_mentions\":[{\"screen_name\":\"EuricSanti\",\"name\":\"Euric Santi\",\"id\":73097979,\"id_str\":\"73097979\",\"indices\":[0,11]},{\"screen_name\":\"ricardomendezc\",\"name\":\"Ricardo\",\"id\":61294918,\"id_str\":\"61294918\",\"indices\":[12,27]}],\"symbols\":[]},\"favorited\":False,\"retweeted\":False,\"filter_level\":\"low\",\"lang\":\"es\",\"timestamp_ms\":\"1618863201138\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c43f1f39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 218740138,\n",
       " 'id_str': '218740138',\n",
       " 'name': 'Alberto J. Damaso S. ¡Carambola!\\ud83d\\udd27',\n",
       " 'screen_name': 'Albertodamaso18',\n",
       " 'location': 'La Romana Rep. Dom.',\n",
       " 'url': 'http:\\\\/\\\\/www.warketingnew.com',\n",
       " 'description': 'Esto no es LinkedIn... ¿Me entendió? \\nPasión + Perseverancia y razón= eso hará que logres todo.\\n¡Sé tu mismo!\\nAmo los mofongos, viajar, acampar, nadar y amar.',\n",
       " 'translator_type': 'none',\n",
       " 'protected': False,\n",
       " 'verified': False,\n",
       " 'followers_count': 358,\n",
       " 'friends_count': 353,\n",
       " 'listed_count': 0,\n",
       " 'favourites_count': 15950,\n",
       " 'statuses_count': 9735,\n",
       " 'created_at': 'Tue Nov 23 04:11:03 +0000 2010',\n",
       " 'utc_offset': None,\n",
       " 'time_zone': None,\n",
       " 'geo_enabled': True,\n",
       " 'lang': None,\n",
       " 'contributors_enabled': False,\n",
       " 'is_translator': False,\n",
       " 'profile_background_color': 'C0DEED',\n",
       " 'profile_background_image_url': 'http:\\\\/\\\\/abs.twimg.com\\\\/images\\\\/themes\\\\/theme1\\\\/bg.png',\n",
       " 'profile_background_image_url_https': 'https:\\\\/\\\\/abs.twimg.com\\\\/images\\\\/themes\\\\/theme1\\\\/bg.png',\n",
       " 'profile_background_tile': True,\n",
       " 'profile_link_color': 'B34800',\n",
       " 'profile_sidebar_border_color': 'C0DEED',\n",
       " 'profile_sidebar_fill_color': 'DDEEF6',\n",
       " 'profile_text_color': '333333',\n",
       " 'profile_use_background_image': True,\n",
       " 'profile_image_url': 'http:\\\\/\\\\/pbs.twimg.com\\\\/profile_images\\\\/1328165946708684803\\\\/8i0lghh0_normal.jpg',\n",
       " 'profile_image_url_https': 'https:\\\\/\\\\/pbs.twimg.com\\\\/profile_images\\\\/1328165946708684803\\\\/8i0lghh0_normal.jpg',\n",
       " 'profile_banner_url': 'https:\\\\/\\\\/pbs.twimg.com\\\\/profile_banners\\\\/218740138\\\\/1612150477',\n",
       " 'default_profile': False,\n",
       " 'default_profile_image': False,\n",
       " 'following': None,\n",
       " 'follow_request_sent': None,\n",
       " 'notifications': None,\n",
       " 'withheld_in_countries': []}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['user']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f29cf81",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkConf,SparkContext\n",
    "from pyspark.streaming import StreamingContext\n",
    "from pyspark.sql import Row,SQLContext\n",
    "import sys\n",
    "import requests\n",
    "# create spark configuration\n",
    "conf = SparkConf()\n",
    "conf.setAppName(\"TwitterStreamApp\")\n",
    "# create spark context with the above configuration\n",
    "sc.setLogLevel(\"ERROR\")\n",
    "# create the Streaming Context from the above spark context with interval size 2 seconds\n",
    "ssc = StreamingContext(sc, 2)\n",
    "# setting a checkpoint to allow RDD recovery\n",
    "ssc.checkpoint(\"checkpoint_TwitterApp\")\n",
    "# read data from port 9009\n",
    "dataStream = ssc.socketTextStream(\"localhost\",9092)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "247f0137",
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_tags_count(new_values, total_sum):\n",
    "\treturn sum(new_values) + (total_sum or 0)\n",
    "\n",
    "def send_df_to_dashboard(df):\n",
    "\t# extract the hashtags from dataframe and convert them into array\n",
    "\ttop_tags = [str(t.hashtag) for t in df.select(\"hashtag\").collect()]\n",
    "\t# extract the counts from dataframe and convert them into array\n",
    "\ttags_count = [p.hashtag_count for p in df.select(\"hashtag_count\").collect()]\n",
    "\t# initialize and send the data through REST API\n",
    "\turl = 'http://localhost:5001/updateData'\n",
    "\trequest_data = {'label': str(top_tags), 'data': str(tags_count)}\n",
    "\tresponse = requests.post(url, data=request_data)\n",
    "\n",
    "def get_sql_context_instance(spark_context):\n",
    "    if ('sqlContextSingletonInstance' not in globals()):\n",
    "        globals()['sqlContextSingletonInstance'] = SQLContext(spark_context)\n",
    "    return globals()['sqlContextSingletonInstance']\n",
    "\n",
    "def process_rdd(time, rdd):\n",
    "    print(\"----------- %s -----------\" % str(time))\n",
    "    try:\n",
    "        # Get spark sql singleton context from the current context\n",
    "        sql_context = get_sql_context_instance(rdd.context)\n",
    "        # convert the RDD to Row RDD\n",
    "        row_rdd = rdd.map(lambda w: Row(hashtag=w[0], hashtag_count=w[1]))\n",
    "        # create a DF from the Row RDD\n",
    "        hashtags_df = sql_context.createDataFrame(row_rdd)\n",
    "        # Register the dataframe as table\n",
    "        hashtags_df.registerTempTable(\"hashtags\")\n",
    "        # get the top 10 hashtags from the table using SQL and print them\n",
    "        hashtag_counts_df = sql_context.sql(\"select hashtag, hashtag_count from hashtags order by hashtag_count desc limit 10\")\n",
    "        hashtag_counts_df.show()\n",
    "        # call this method to prepare top 10 hashtags DF and send them\n",
    "        send_df_to_dashboard(hashtag_counts_df)\n",
    "    except:\n",
    "        e = sys.exc_info()[0]\n",
    "        print(\"Error: %s\" % e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f734553",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split each tweet into words\n",
    "words = dataStream.flatMap(lambda line: line.split(\" \"))\n",
    "# filter the words to get only hashtags, then map each hashtag to be a pair of (hashtag,1)\n",
    "hashtags = words.filter(lambda w: '#' in w).map(lambda x: (x, 1))\n",
    "# adding the count of each hashtag to its last count\n",
    "tags_totals = hashtags.updateStateByKey(aggregate_tags_count)\n",
    "# do processing for each RDD generated in each interval\n",
    "tags_totals.foreachRDD(process_rdd)\n",
    "# start the streaming computation\n",
    "ssc.start()\n",
    "# wait for the streaming to finish\n",
    "ssc.awaitTermination()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57618841",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
